linear_method {

training_data {
format: TEXT
text: LIBSVM
file: "data/train/part.*"
}

model_output {
format: TEXT
file: "model/rcv1_batch_l1lr"
}

loss {
type: LOGIT
}

# lambda * |w|_1
penalty {
type: L1
lambda: 1
}

learning_rate {
type: CONSTANT
alpha: 1
}

darlin {

# turn it off to elimiate the randomness, but may affects the convergence rate
random_feature_block_order : true
# block-coordinate updating. We divide a feature group into feature_block_ratio
# x nnz_feature_per_instance blocks. If = 0, then use all features
feature_block_ratio : 4
# max number pass of traing data
max_pass_of_data : 20
# bounded-delay consistency
max_block_delay : 0
# convergance critiria. stop if the relative objective <= epsilon
epsilon : 1e-4
# features which occurs <= *tail_feature_count* will be filtered before training
tail_feature_freq : 0

local_cache {
format: BIN
file: "data/cache/train"
}


# decrease these numbers for harder dataset
[PS.LM.delta_init_value] : 5
[PS.LM.delta_max_value] : 10
# increasing this number reduces the effect of kkt filter.
[PS.LM.kkt_filter_threshold_ratio] : 100
}

}
